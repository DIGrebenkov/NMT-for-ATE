{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ade08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ahocorasick\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce733840",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP_TOKEN = ' ; '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f9baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  ABBYY Retrieval & Morphology Engine\\nВ сообщен...   \n",
      "1  Речевые формулы в диалоге\\nПредложенная класси...   \n",
      "2  Географические названия и полнотекстовые докум...   \n",
      "3  Методы автоматического построения специализиро...   \n",
      "4  Закономерности построения дискурсивной последо...   \n",
      "\n",
      "                                               label  \n",
      "0  [[0, 35], [6, 15], [18, 35], [29, 35], [69, 88...  \n",
      "1  [[0, 15], [18, 25], [74, 99], [134, 140], [175...  \n",
      "2  [[0, 23], [26, 50], [54, 68], [169, 190], [181...  \n",
      "3  [[7, 63], [34, 63], [54, 63], [92, 128], [119,...  \n",
      "4  [[26, 57], [62, 76], [251, 265], [266, 280], [...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json ('train_t1_v1.jsonl', lines = True)\n",
    "df.drop (columns = ['id', 'keywords'], inplace = True)\n",
    "print (df.head ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbdb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text (text, segments, delimiters = ['...', '.', '?!', '?', '!']):\n",
    "\n",
    "    # Фильтрация\n",
    "    #text = re.sub ('[“”]', '\\\"', text)\n",
    "\n",
    "    # Создаем регулярное выражение для разделителей\n",
    "    delimiters_pattern = '|'.join (map (re.escape, delimiters))\n",
    "    \n",
    "    # Разделяем текст на абзацы\n",
    "    #paragraphs = text.split ('\\n')\n",
    "    paragraphs = re.split (f'(?<=\\n[ ]*)', text)\n",
    "    \n",
    "    # Список для хранения предложений и их индексов\n",
    "    sentences_with_segments = []\n",
    "    \n",
    "    current_start_index = 0\n",
    "    # Обрабатываем каждый абзац\n",
    "    for paragraph in paragraphs:\n",
    "        # Разделяем абзац на предложения\n",
    "        sentences = re.split (f'(?<=[{delimiters_pattern}] )(?=[A-ZА-ЯЁ])', paragraph)#.strip ())\n",
    "\n",
    "        #print (f'\\nРассматривается параграф: <{paragraph}>.')\n",
    "        \n",
    "        # Сопоставляем предложения с сегментами\n",
    "        for sentence in sentences:\n",
    "            #print ('> Предложение:', sentence)\n",
    "            # Ищем индексы символов для текущего предложения\n",
    "            start_index = current_start_index\n",
    "            end_index = start_index + len (sentence)\n",
    "\n",
    "            #print (f'Current sentence (from split): <{sentence}>')\n",
    "            #print (f'Current sentence (by indices): <{text [start_index: end_index]}>')\n",
    "            #print (f'Sentence start index: {start_index}, end index: {end_index}.')\n",
    "            #print (f'Segments to match: {segments}')\n",
    "\n",
    "            matched_segments = [\n",
    "                text [start: end] for start, end in segments if start >= start_index and end <= end_index\n",
    "            ]\n",
    "            sentences_with_segments.append ((sentence, matched_segments))\n",
    "\n",
    "            #current_start_index += len (sentence) + MAGIC_NUMBER\n",
    "            current_start_index = end_index\n",
    "\n",
    "\n",
    "            #print ('Термины:', matched_segments)\n",
    "    \n",
    "    return sentences_with_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885d7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_text = []\n",
    "parallel_label = []\n",
    "#for i, row in tqdm (df.iterrows (), total = df.shape [0], desc = \"Processing texts: \"):\n",
    "for i, row in df.iterrows ():\n",
    "    text = row ['text']\n",
    "    segments = row ['label']\n",
    "    splitted = split_text (text, segments)\n",
    "    for sentence, terms in splitted:\n",
    "        parallel_text.append (sentence)\n",
    "        constructed_label = ''\n",
    "        for term in terms:\n",
    "            constructed_label += term.strip () + SEP_TOKEN\n",
    "        if len (constructed_label) > 0:\n",
    "            parallel_label.append (constructed_label [: - len (SEP_TOKEN)])\n",
    "        else:\n",
    "            parallel_label.append ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03400656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9761"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_terms = set ()\n",
    "\n",
    "for line in parallel_label:\n",
    "    \n",
    "    all_train_terms |= set (line.split (SEP_TOKEN))\n",
    "\n",
    "all_train_terms -= set ([''])\n",
    "len (all_train_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211777b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_substrings (phrases, strings):\n",
    "    # Создаем автомат\n",
    "    A = ahocorasick.Automaton()\n",
    "    \n",
    "    # Добавляем все подстроки в автомат\n",
    "    for idx, phrase in enumerate (phrases):\n",
    "        A.add_word (phrase, (idx, phrase))\n",
    "    \n",
    "    # Завершаем построение автомата\n",
    "    A.make_automaton ()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Ищем подстроки в каждой строке\n",
    "    for s in strings:\n",
    "        found = []\n",
    "        for end_index, (idx, phrase) in A.iter (s):\n",
    "            start_index = end_index - len (phrase) + 1\n",
    "\n",
    "            # Не хочу цеплять подстроки внутри слов\n",
    "            if start_index > 0 and s [start_index - 1].isalpha ():\n",
    "                continue\n",
    "            if end_index + 1 < len (s) and s [end_index + 1].isalpha ():\n",
    "                continue\n",
    "\n",
    "            found.append ((start_index, end_index + 1, phrase))\n",
    "        \n",
    "        results [s] = found\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Пример использования\n",
    "#phrases = {\"пример\", \"строка\", \"поиск\"}\n",
    "#strings = [\"это пример строки для поиска\", \"другая строка без совпадений\", \"поиск в строке\"]\n",
    "\n",
    "#results = find_substrings (phrases, strings)\n",
    "\n",
    "#for string, matches in results.items ():\n",
    "#    print(f\"В строке: '{string}' найдены совпадения: {matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e609236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53) Item (408, 446) - <Грамматического словаря А.А. Зализняка> is in labels, but not in pred.\n",
      "(96) Item (877, 905) - <“Анны Карениной” Л. Толстого> is in labels, but not in pred.\n",
      "(107) Item (456, 511) - <«Грамматического словаря русского языка» А.А. Зализняка> is in labels, but not in pred.\n",
      "(113) Item (316, 370) - <«Грамматический словарь русского языка» А.А. Зализняка> is in labels, but not in pred.\n",
      "(144) Item (135, 167) - <пирамидальных сетей В.П. Гладуна> is in labels, but not in pred.\n",
      "(151) Item (752, 789) - <стихотворения А.С. Пушкина “Памятник”> is in labels, but not in pred.\n",
      "(175) Item (790, 852) - <Толковом словаре русского языка (Под ред. проф. Д. Н. Ушакова)> is in labels, but not in pred.\n",
      "(187) Item (987, 1009) - <словаря А.А. Зализняка> is in labels, but not in pred.\n",
      "(256) Item (348, 372) - <концепции М.А. Кронгауза> is in labels, but not in pred.\n",
      "(332) Item (149, 166) - <говору с. Пустоша> is in labels, but not in pred.\n",
      "(415) Item (405, 435) - <работе А. Б. Лорда «Сказитель»> is in labels, but not in pred.\n",
      "(506) Item (100, 121) - <словарю С. И. Ожегова> is in labels, but not in pred.\n",
      "(506) Item (382, 411) - <словаре С. И. Ожегова 1989 г.> is in labels, but not in pred.\n",
      "(730) Item (225, 266) - <теории вежливости П. Браун и С. Левинсона> is in labels, but not in pred.\n",
      "(730) Item (192, 223) - <теории импликатуры Г. П. Грайса> is in labels, but not in pred.\n",
      "(777) Item (892, 957) - <системы просодической автосегментной транскрипции Дж. Пьерхамберт> is in labels, but not in pred.\n",
      "Total 6686 terms are in pred, but not labels.\n",
      "Total 16 terms are in labels, but not pred.\n"
     ]
    }
   ],
   "source": [
    "testres = find_substrings (all_train_terms, df ['text'].tolist ())\n",
    "#testres = find_substrings (all_train_terms, parallel_text)\n",
    "\n",
    "i = 0\n",
    "\n",
    "count_pred_not_labels = 0\n",
    "count_labels_not_pred = 0\n",
    "\n",
    "for string, matches in testres.items ():\n",
    "    slices = [[item [0], item [1]] for item in matches]\n",
    "    slices.sort (key = lambda x: x [0])\n",
    "\n",
    "    pred = set ([tuple (item) for item in slices])\n",
    "    labl = set ([tuple (item) for item in df ['label'] [i]])\n",
    "\n",
    "    diff = pred - labl\n",
    "    for item in diff:\n",
    "        #print (f'({i}) Item {item} - <{df [\"text\"] [i] [item [0]: item [1]]}> is in pred, but not in labels.')\n",
    "        count_pred_not_labels += 1\n",
    "\n",
    "    diff = labl - pred\n",
    "    for item in diff:\n",
    "        print (f'({i}) Item {item} - <{df [\"text\"] [i] [item [0]: item [1]]}> is in labels, but not in pred.')\n",
    "        count_labels_not_pred += 1\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print (f'Total {count_pred_not_labels} terms are in pred, but not labels.')\n",
    "print (f'Total {count_labels_not_pred} terms are in labels, but not pred.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5589fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success log:\n",
    "# Total X terms are in labels, but not pred/\n",
    "# X: 993 -> 269 -> 613 (*_*) -> 1003 (-_-) -> 16 (˶ᵔ ᵕ ᵔ˶)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ce7b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('К проблеме понимания несегментированного текста (на материале метеорологических телеграмм)\\n',\n",
       "  ['несегментированного текста', 'метеорологических телеграмм']),\n",
       " ('В фокусе внимания данной работы находится проблема восстановления структуры несегментированного текста. ',\n",
       "  ['восстановления структуры несегментированного текста',\n",
       "   'несегментированного текста']),\n",
       " ('Описывается процедура сегментации, которая осуществляет декомпозицию исходной лексической цепочки в последовательность тематически связных фрагментов, в рамках которых возможна семантическая интерпретация. ',\n",
       "  ['сегментации',\n",
       "   'декомпозицию',\n",
       "   'лексической цепочки',\n",
       "   'тематически связных фрагментов',\n",
       "   'семантическая интерпретация']),\n",
       " ('Определяется нарративная структура текста в терминах типа сценария (прогрессивный или рекуррентный) и структуры эпизода (параллельная или последовательная). ',\n",
       "  ['нарративная структура текста',\n",
       "   'терминах',\n",
       "   'сценария',\n",
       "   'прогрессивный',\n",
       "   'рекуррентный',\n",
       "   'структуры эпизода',\n",
       "   'параллельная',\n",
       "   'последовательная']),\n",
       " ('Тематическая сегментация и анализ нарративной структуры текста позволяют установить семантические связи (сферы действия) локативных и темпоральных модификаторов.',\n",
       "  ['Тематическая сегментация',\n",
       "   'анализ нарративной структуры текста',\n",
       "   'нарративной структуры текста',\n",
       "   'семантические связи',\n",
       "   'сферы действия',\n",
       "   'локативных',\n",
       "   'темпоральных модификаторов',\n",
       "   'модификаторов'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_text (df ['text'] [5], df ['label'] [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "069e0c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['К проблеме понимания несегментированного текста (на материале метеорологических телеграмм)\\n',\n",
       " 'В фокусе внимания данной работы находится проблема восстановления структуры несегментированного текста. Описывается процедура сегментации, которая осуществляет декомпозицию исходной лексической цепочки в последовательность тематически связных фрагментов, в рамках которых возможна семантическая интерпретация. Определяется нарративная структура текста в терминах типа сценария (прогрессивный или рекуррентный) и структуры эпизода (параллельная или последовательная). Тематическая сегментация и анализ нарративной структуры текста позволяют установить семантические связи (сферы действия) локативных и темпоральных модификаторов.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#paragraph = 'Предложенная классификация, как и многие другие лингвистические типологии, допускает пересечения. Например, идиома врать готово в последовательности реплик [- Честное слово] - Врать готово, с одной стороны, является комментарием, а с другой – обладает некоторыми характеристиками формул ответа: иллокутивно вынуждается предшествующей репликой и повторяет ее некоторые фонетические особенности. Кроме того, поскольку оценивается искренность предшествующей клятвы, данную идиому можно рассматривать и как формулу эпистемической модальности.'\n",
    "text = \"К проблеме понимания несегментированного текста (на материале метеорологических телеграмм)\\nВ фокусе внимания данной работы находится проблема восстановления структуры несегментированного текста. Описывается процедура сегментации, которая осуществляет декомпозицию исходной лексической цепочки в последовательность тематически связных фрагментов, в рамках которых возможна семантическая интерпретация. Определяется нарративная структура текста в терминах типа сценария (прогрессивный или рекуррентный) и структуры эпизода (параллельная или последовательная). Тематическая сегментация и анализ нарративной структуры текста позволяют установить семантические связи (сферы действия) локативных и темпоральных модификаторов.\"\n",
    "\n",
    "delimiters = ['...', '.', '?!', '?', '!']\n",
    "\n",
    "delimiters_pattern = '|'.join (map (re.escape, delimiters))\n",
    "\n",
    "paragraphs = re.split (f'(?<=\\n)', text)\n",
    "\n",
    "paragraphs\n",
    "\n",
    "#sentences = re.split (f'(?<=[{delimiters_pattern}]) (?=[A-ZА-ЯЁ])', paragraph.strip ())\n",
    "\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee53fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_splitter (text, delimiters = ['...', '.', '?!', '?', '!']):\n",
    "\n",
    "    delimiters_pattern = '|'.join (map (re.escape, delimiters))\n",
    "    paragraphs = re.split (f'(?<=\\n[ ]*)', text)\n",
    "    \n",
    "    sentences_with_indices = []\n",
    "    current_start_index = 0\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "\n",
    "        sentences = re.split (f'(?<=[{delimiters_pattern}] )(?=[A-ZА-ЯЁ])', paragraph)#.strip ())\n",
    "\n",
    "        for sentence in sentences:\n",
    "\n",
    "            start_index = current_start_index\n",
    "            end_index = start_index + len (sentence)\n",
    "\n",
    "            sentences_with_indices.append ((sentence, (start_index, end_index)))\n",
    "\n",
    "            current_start_index = end_index\n",
    "    \n",
    "    return sentences_with_indices\n",
    "\n",
    "def one_finder (text, phrases):\n",
    "\n",
    "    A = ahocorasick.Automaton ()\n",
    "    \n",
    "    for idx, phrase in enumerate (phrases):\n",
    "        A.add_word (phrase, (idx, phrase))\n",
    "    \n",
    "    A.make_automaton ()\n",
    "    \n",
    "    found = []\n",
    "    for end_index, (idx, phrase) in A.iter (text):\n",
    "        start_index = end_index - len (phrase) + 1\n",
    "\n",
    "        if start_index > 0 and text [start_index - 1].isalpha ():\n",
    "            continue\n",
    "        if end_index + 1 < len (text) and text [end_index + 1].isalpha ():\n",
    "            continue\n",
    "\n",
    "        found.append ((start_index, end_index + 1, phrase))\n",
    "    \n",
    "    return found\n",
    "\n",
    "def answerer (text, term_set = all_train_terms):\n",
    "    sentences_w_ind = raw_splitter (text)\n",
    "\n",
    "    answers = []\n",
    "    for sentence, (start, end) in sentences_w_ind:\n",
    "        found = one_finder (sentence, term_set)\n",
    "        answers += [[item [0] + start, item [1] + start] for item in found]\n",
    "\n",
    "    return answers\n",
    "\n",
    "def comparator (pred, labl):\n",
    "\n",
    "    pred = set ([tuple (item) for item in pred])\n",
    "    labl = set ([tuple (item) for item in labl])\n",
    "\n",
    "    true_positives = len (pred & labl)\n",
    "    false_positives = len (pred - labl)\n",
    "    false_negatives = len (labl - pred)\n",
    "\n",
    "    return true_positives, false_positives, false_negatives\n",
    "\n",
    "def metricator (preds, labels):\n",
    "\n",
    "    tps_sum = 0\n",
    "    fps_sum = 0\n",
    "    fns_sum = 0 \n",
    "\n",
    "    for i in range (len (labels)):\n",
    "\n",
    "        true_positives, false_positives, false_negatives = comparator (preds [i], labels [i])\n",
    "\n",
    "        tps_sum += true_positives   # Истинно положительные\n",
    "        fps_sum += false_positives     # Ложноположительные\n",
    "        fns_sum += false_negatives     # Ложноотрицательные\n",
    "\n",
    "    precision = tps_sum / (tps_sum + fps_sum) if (tps_sum + fps_sum) > 0 else 0\n",
    "    recall = tps_sum / (tps_sum + fns_sum) if (tps_sum + fns_sum) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a7c4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 15],\n",
       " [0, 35],\n",
       " [18, 35],\n",
       " [29, 35],\n",
       " [69, 88],\n",
       " [112, 119],\n",
       " [147, 159],\n",
       " [194, 226],\n",
       " [205, 226],\n",
       " [258, 280],\n",
       " [274, 280],\n",
       " [283, 307],\n",
       " [300, 307],\n",
       " [314, 323],\n",
       " [308, 343],\n",
       " [326, 343],\n",
       " [337, 343],\n",
       " [372, 391]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerer (df ['text'] [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c41c3646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9444444444444444, 1.0, 0.9714285714285714)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricator ([answerer (df ['text'] [0])], [df ['label'] [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3399e7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nanswers_bydict = []\\n\\nfor i, row in tqdm (df.iterrows ()):\\n    answers_bydict.append (answerer (row ['text']))\\n\\nlabels = df ['label'].tolist ()\\n\\nmetricator (answers_bydict, labels)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "answers_bydict = []\n",
    "\n",
    "for i, row in tqdm (df.iterrows ()):\n",
    "    answers_bydict.append (answerer (row ['text']))\n",
    "\n",
    "labels = df ['label'].tolist ()\n",
    "\n",
    "metricator (answers_bydict, labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f232022",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_txt, temp_data_txt, train_labels_txt, temp_labels_txt = train_test_split (df ['text'], df ['label'], test_size = 0.2, random_state = 14)\n",
    "val_data_txt, test_data_txt, val_labels_txt, test_labels_txt = train_test_split (temp_data_txt, temp_labels_txt, test_size = 0.5, random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a88b0af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8048"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_train_terms = set ()\n",
    "\n",
    "train_data = train_data_txt.tolist ()\n",
    "train_labels = train_labels_txt.tolist ()\n",
    "\n",
    "for i in range (len (train_data)):\n",
    "\n",
    "    terms = [train_data [i] [item [0]: item [1]] for item in train_labels [i]]\n",
    "    \n",
    "    only_train_terms |= set (terms)\n",
    "\n",
    "only_train_terms -= set ([''])\n",
    "len (only_train_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a74c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:04<00:00, 20.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6165980795610425, 0.4928728070175439, 0.5478366849482023)\n",
      "489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_data = val_data_txt.tolist ()\n",
    "val_labels = val_labels_txt.tolist ()\n",
    "\n",
    "only_val_terms = set ()\n",
    "for i in range (len (val_data)):\n",
    "    terms = [val_data [i] [item [0]: item [1]] for item in val_labels [i]]\n",
    "    only_val_terms |= set (terms)\n",
    "only_val_terms -= set ([''])\n",
    "len (only_val_terms)\n",
    "\n",
    "answers_bydict = []\n",
    "for item in tqdm (val_data):\n",
    "    answers_bydict.append (answerer (item, only_train_terms))\n",
    "\n",
    "print (metricator (answers_bydict, val_labels))\n",
    "print (len (only_train_terms & only_val_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e5c834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:04<00:00, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5824175824175825, 0.4836285560923242, 0.5284457478005864)\n",
      "464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_data = test_data_txt.tolist ()\n",
    "val_labels = test_labels_txt.tolist ()\n",
    "\n",
    "only_test_terms = set ()\n",
    "for i in range (len (val_data)):\n",
    "    terms = [val_data [i] [item [0]: item [1]] for item in val_labels [i]]\n",
    "    only_test_terms |= set (terms)\n",
    "only_test_terms -= set ([''])\n",
    "len (only_test_terms)\n",
    "\n",
    "answers_bydict = []\n",
    "for item in tqdm (val_data):\n",
    "    answers_bydict.append (answerer (item, only_train_terms))\n",
    "\n",
    "print (metricator (answers_bydict, val_labels))\n",
    "print (len (only_train_terms & only_test_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "915dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Терминов в обучающем наборе: 8048.\n",
      "Терминов в валидационном наборе: 1352.\n",
      "Терминов в тестовом наборе: 1350.\n",
      "\n",
      "При этом пересечений обучающего и валидационного: 489,\n",
      "         пересечений обучающего и тестового:      464\n",
      "     пересечений валидационного и тестового:      181\n"
     ]
    }
   ],
   "source": [
    "print (f'Терминов в обучающем наборе: {len (only_train_terms)}.')\n",
    "print (f'Терминов в валидационном наборе: {len (only_val_terms)}.')\n",
    "print (f'Терминов в тестовом наборе: {len (only_test_terms)}.')\n",
    "\n",
    "print ()\n",
    "\n",
    "print (f'При этом пересечений обучающего и валидационного: {len (only_train_terms & only_val_terms)},')\n",
    "print (f'         пересечений обучающего и тестового:      {len (only_train_terms & only_test_terms)}')\n",
    "print (f'     пересечений валидационного и тестового:      {len (only_val_terms & only_test_terms)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75e10053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  АВТОМАТИЧЕСКИЙ АНАЛИЗ ТОНАЛЬНОСТИ ТЕКСТОВ НА О...   \n",
      "1  InBASE: ТЕХНОЛОГИЯ ПОСТРОЕНИЯ ЕЯ-ИНТЕРФЕЙСОВ К...   \n",
      "2  Выражение уважительности с помощью личных мест...   \n",
      "3  ДА ЧЕРТ ЛИ В ДЕТАЛЯХ?.. МЕРА ДЛЯ ОЦЕНКИ СОВПАД...   \n",
      "4  КОРПУСНАЯ ОЦЕНКА СОЧЕТАЕМОСТИ СЛОВ С ИСПОЛЬЗОВ...   \n",
      "\n",
      "                                               label  \n",
      "0  [[0, 33, specific], [22, 33, specific], [52, 7...  \n",
      "1  [[0, 6, nomen], [19, 44, specific], [30, 44, s...  \n",
      "2  [[0, 24, specific], [35, 53, specific], [42, 5...  \n",
      "3  [[51, 70, specific], [61, 70, specific], [116,...  \n",
      "4  [[0, 16, specific], [17, 34, specific], [30, 3...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def label_constructor (labels):\n",
    "    res = []\n",
    "    for label in labels:\n",
    "        one_label = []\n",
    "        for start, end, cls in label:\n",
    "            one_label.append ([start, end])\n",
    "        res.append (one_label)\n",
    "    return res\n",
    "\n",
    "df_2 = pd.read_json ('./test_data/test1_t12_full_v2.jsonl', lines = True, encoding = 'utf8')\n",
    "df_2 = df_2 [['text', 'label']]\n",
    "print (df_2.head ())\n",
    "\n",
    "df_2 ['label'] = label_constructor (df_2 ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f1f5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9777"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_train_terms = set ()\n",
    "\n",
    "train_data = df ['text'].tolist ()\n",
    "train_labels = df ['label'].tolist ()\n",
    "\n",
    "for i in range (len (train_data)):\n",
    "\n",
    "    terms = [train_data [i] [item [0]: item [1]] for item in train_labels [i]]\n",
    "    \n",
    "    only_train_terms |= set (terms)\n",
    "\n",
    "only_train_terms -= set ([''])\n",
    "len (only_train_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "072b7f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:07<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5832476875642343, 0.4797125950972105, 0.5264378478664193)\n",
      "448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_data = df_2 ['text'].tolist ()\n",
    "val_labels = df_2 ['label'].tolist ()\n",
    "\n",
    "val_data_txt, test_data_txt, val_labels_txt, test_labels_txt = train_test_split (val_data, val_labels, test_size = 0.5, random_state = 14)\n",
    "\n",
    "only_val_terms = set ()\n",
    "for i in range (len (val_data_txt)):\n",
    "    terms = [val_data_txt [i] [item [0]: item [1]] for item in val_labels_txt [i]]\n",
    "    only_val_terms |= set (terms)\n",
    "only_val_terms -= set ([''])\n",
    "len (only_val_terms)\n",
    "\n",
    "answers_bydict = []\n",
    "for item in tqdm (val_data_txt):\n",
    "    answers_bydict.append (answerer (item, only_train_terms))\n",
    "\n",
    "print (metricator (answers_bydict, val_labels_txt))\n",
    "print (len (only_train_terms & only_val_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec5e743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:08<00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5896964121435143, 0.4874524714828897, 0.5337218984179851)\n",
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "only_val_terms = set ()\n",
    "for i in range (len (test_data_txt)):\n",
    "    terms = [test_data_txt [i] [item [0]: item [1]] for item in test_labels_txt [i]]\n",
    "    only_val_terms |= set (terms)\n",
    "only_val_terms -= set ([''])\n",
    "len (only_val_terms)\n",
    "\n",
    "answers_bydict = []\n",
    "for item in tqdm (test_data_txt):\n",
    "    answers_bydict.append (answerer (item, only_train_terms))\n",
    "\n",
    "print (metricator (answers_bydict, test_labels_txt))\n",
    "print (len (only_train_terms & only_val_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c516c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d99fc5c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_set\u001b[39m (tensor, ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m):\n\u001b[0;32m      3\u001b[0m     separator: \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SEP_TOKEN \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m▁<extra_id_0>\u001b[39m\u001b[38;5;124m'\u001b[39m: separator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<extra_id_0>\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "def get_set (tensor, ground_truth = True, tokenizer = tokenizer):\n",
    "\n",
    "    separator: str\n",
    "    if SEP_TOKEN == '▁<extra_id_0>': separator = '<extra_id_0>'\n",
    "    else: separator = SEP_TOKEN\n",
    "\n",
    "    res: set\n",
    "\n",
    "    if ground_truth:\n",
    "        eos_idx = (tensor == 1).nonzero ()\n",
    "        if eos_idx.numel () > 0:\n",
    "            eos_idx = int (eos_idx [0] [0])\n",
    "        else:\n",
    "            eos_idx = len (tensor)\n",
    "        seq = tensor [:eos_idx]\n",
    "    \n",
    "    else:\n",
    "        seq = tensor [tensor != 0]\n",
    "        seq = seq [seq != 1]\n",
    "    \n",
    "    txt = tokenizer.decode (seq)\n",
    "    res = set ([item.strip () for item in txt.split (separator)])\n",
    "\n",
    "    if len (res) > 1:\n",
    "        res -= set ([''])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def sanity_check (preds, labels, to_print = False):\n",
    "\n",
    "    tps_sum = 0\n",
    "    fps_sum = 0\n",
    "    fns_sum = 0 \n",
    "\n",
    "    for i in range (len (labels)):\n",
    "        predicted_set = get_set (preds [i], ground_truth = False)\n",
    "        true_set = get_set (labels [i])\n",
    "\n",
    "        if to_print: print (f'True: {true_set}\\nPred: {predicted_set}')\n",
    "\n",
    "        tps_sum += len (true_set & predicted_set)  # Истинно положительные\n",
    "        fps_sum += len (predicted_set - true_set)     # Ложноположительные\n",
    "        fns_sum += len (true_set - predicted_set)     # Ложноотрицательные\n",
    "\n",
    "    precision = tps_sum / (tps_sum + fps_sum) if (tps_sum + fps_sum) > 0 else 0\n",
    "    recall = tps_sum / (tps_sum + fns_sum) if (tps_sum + fns_sum) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e799d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "SEQ_MAX_LENGTH = 150\n",
    "\n",
    "def predict_with_model (texts, model, tokenizer):\n",
    "\n",
    "    model.eval ()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for text in tqdm (texts):\n",
    "\n",
    "        sentences_w_ind = raw_splitter (text)\n",
    "\n",
    "        answers = []\n",
    "        for sentence, (start, end) in sentences_w_ind:\n",
    "\n",
    "            sentence_tokenized = tokenizer (sentence, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "\n",
    "            with torch.no_grad ():\n",
    "\n",
    "                input_ids = sentence_tokenized ['input_ids'].to (model.device)\n",
    "                attention_mask = sentence_tokenized ['attention_mask'].to (model.device)\n",
    "\n",
    "                out = model.generate (input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "                term_set = get_set (out)\n",
    "\n",
    "            found = one_finder (sentence, term_set)\n",
    "            answers += [[item [0] + start, item [1] + start] for item in found]\n",
    "\n",
    "        predictions.append (answers)\n",
    "\n",
    "    return (predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
