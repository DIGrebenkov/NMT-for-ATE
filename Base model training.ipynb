{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ahocorasick\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, MT5ForConditionalGeneration, get_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP_TOKEN = '▁<extra_id_0>'\n",
    "INPUT_PREFIX = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json ('train_t1_v1.jsonl', lines = True)\n",
    "df.drop (columns = ['id', 'keywords'], inplace = True)\n",
    "print (df.head ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text (text, segments, delimiters = ['...', '.', '?!', '?', '!']):\n",
    "\n",
    "    delimiters_pattern = '|'.join (map (re.escape, delimiters))\n",
    "\n",
    "    # Разделение текста на абзацы\n",
    "    paragraphs = re.split (f'(?<=\\n[ ]*)', text)\n",
    "    \n",
    "    sentences_with_segments = []\n",
    "    \n",
    "    current_start_index = 0\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        # Разделение абзацев на предложения\n",
    "        sentences = re.split (f'(?<=[{delimiters_pattern}] )(?=[A-ZА-ЯЁ])', paragraph)#.strip ())\n",
    "        \n",
    "        # Сопоставление предложений с сегментами разметки\n",
    "        for sentence in sentences:\n",
    "\n",
    "            start_index = current_start_index\n",
    "            end_index = start_index + len (sentence)\n",
    "\n",
    "            matched_segments = [\n",
    "                text [start: end] for start, end in segments if start >= start_index and end <= end_index\n",
    "            ]\n",
    "            sentences_with_segments.append ((sentence, matched_segments))\n",
    "\n",
    "            current_start_index = end_index\n",
    "    \n",
    "    return sentences_with_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c09cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_txt, temp_data_txt, train_labels_txt, temp_labels_txt = train_test_split (df ['text'], df ['label'], test_size = 0.2, random_state = 14)\n",
    "#val_data_txt, test_data_txt, val_labels_txt, test_labels_txt = train_test_split (temp_data_txt, temp_labels_txt, test_size = 0.5, random_state = 14)\n",
    "\n",
    "train_data_txt = df ['text']\n",
    "train_labels_txt = df ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca20ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_constructor (labels):\n",
    "    res = []\n",
    "    for label in labels:\n",
    "        one_label = []\n",
    "        for start, end, cls in label:\n",
    "            one_label.append ([start, end])\n",
    "        res.append (one_label)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_json ('./test_data/test1_t12_full_v2.jsonl', lines = True)\n",
    "df_2 = df_2 [['text', 'label']]\n",
    "print (df_2.head ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec26e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_txt, test_data_txt, val_labels_txt, test_labels_txt = train_test_split (df_2 ['text'], df_2 ['label'], test_size = 0.5, random_state = 14)\n",
    "\n",
    "#val_data_txt = df_2 ['text']\n",
    "#val_labels_txt = df_2 ['label']\n",
    "\n",
    "#test_data_txt = val_data_txt\n",
    "#test_labels_txt = val_labels_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd417b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lst = train_data_txt.tolist ()\n",
    "train_labels_lst = train_labels_txt.tolist ()\n",
    "\n",
    "parallel_text = []\n",
    "parallel_label = []\n",
    "\n",
    "for i in range (len (train_data_lst)):\n",
    "    text = train_data_lst [i]\n",
    "    segments = train_labels_lst [i]\n",
    "    splitted = split_text (text, segments)\n",
    "    for sentence, terms in splitted:\n",
    "        parallel_text.append (INPUT_PREFIX + sentence)\n",
    "        constructed_label = ''\n",
    "        for term in terms:\n",
    "            constructed_label += term.strip () + SEP_TOKEN\n",
    "        if len (constructed_label) > 0:\n",
    "            parallel_label.append (constructed_label [: - len (SEP_TOKEN)])\n",
    "        else:\n",
    "            parallel_label.append ('')\n",
    "\n",
    "\n",
    "val_data_lst = val_data_txt.tolist ()\n",
    "val_labels_lst = label_constructor (val_labels_txt)\n",
    "parallel_text_val = []\n",
    "parallel_label_val = []\n",
    "for i in range (len (val_data_lst)):\n",
    "    text = val_data_lst [i]\n",
    "    segments = val_labels_lst [i]\n",
    "    splitted = split_text (text, segments)\n",
    "    for sentence, terms in splitted:\n",
    "        parallel_text_val.append (INPUT_PREFIX + sentence)\n",
    "        constructed_label = ''\n",
    "        for term in terms:\n",
    "            constructed_label += term.strip () + SEP_TOKEN\n",
    "        if len (constructed_label) > 0:\n",
    "            parallel_label_val.append (constructed_label [: - len (SEP_TOKEN)])\n",
    "        else:\n",
    "            parallel_label_val.append ('')\n",
    "\n",
    "\n",
    "test_data_lst = test_data_txt.tolist ()\n",
    "test_labels_lst = label_constructor (test_labels_txt)\n",
    "parallel_text_test = []\n",
    "parallel_label_test = []\n",
    "for i in range (len (test_data_lst)):\n",
    "    text = test_data_lst [i]\n",
    "    segments = test_labels_lst [i]\n",
    "    splitted = split_text (text, segments)\n",
    "    for sentence, terms in splitted:\n",
    "        parallel_text_test.append (INPUT_PREFIX + sentence)\n",
    "        constructed_label = ''\n",
    "        for term in terms:\n",
    "            constructed_label += term.strip () + SEP_TOKEN\n",
    "        if len (constructed_label) > 0:\n",
    "            parallel_label_test.append (constructed_label [: - len (SEP_TOKEN)])\n",
    "        else:\n",
    "            parallel_label_test.append ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_MODEL_NAME = 'cointegrated/rut5-small'\n",
    "\n",
    "SEQ_MAX_LENGTH = 150\n",
    "BATCH_SIZE = 4\n",
    "EVAL_BATCH_SIZE = 16\n",
    "\n",
    "ENABLE_LABEL_FIX = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a964318",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained (USED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenizer (parallel_text, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "train_labels = tokenizer (parallel_label, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "\n",
    "val_data = tokenizer (parallel_text_val, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "val_labels = tokenizer (parallel_label_val, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "\n",
    "test_data = tokenizer (parallel_text_test, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "test_labels = tokenizer (parallel_label_test, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_padding (labels):\n",
    "    for i in range (0, len (labels ['input_ids'])):\n",
    "        labels ['input_ids'] [i] = torch.tensor ([labl if labl != 0 else - 100 for labl in labels ['input_ids'] [i]])\n",
    "\n",
    "    return labels\n",
    "\n",
    "if ENABLE_LABEL_FIX:\n",
    "    rse = replace_padding (train_labels)\n",
    "    train_labels = rse\n",
    "\n",
    "    rse = replace_padding (val_labels)\n",
    "    val_labels = rse\n",
    "\n",
    "    rse = replace_padding (test_labels)\n",
    "    test_labels = rse\n",
    "\n",
    "train_labels ['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset (Dataset):\n",
    "    def __init__ (self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__ (self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings ['input_ids'] [idx],\n",
    "            'attention_mask': self.encodings ['attention_mask'] [idx],\n",
    "            'labels': self.labels ['input_ids'] [idx]\n",
    "        }\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len (self.encodings ['input_ids'])\n",
    "\n",
    "train_dataset = Seq2SeqDataset (train_data, train_labels)\n",
    "val_dataset = Seq2SeqDataset (val_data, val_labels)\n",
    "test_dataset = Seq2SeqDataset (test_data, test_labels)\n",
    "\n",
    "train_loader = DataLoader (train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader (val_dataset, batch_size = EVAL_BATCH_SIZE)\n",
    "test_loader = DataLoader (test_dataset, batch_size = EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b16df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained (USED_MODEL_NAME)\n",
    "\n",
    "model.to (device)\n",
    "print (model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set (tensor, ground_truth = True, tokenizer = tokenizer):\n",
    "\n",
    "    separator: str\n",
    "    if SEP_TOKEN == '▁<extra_id_0>': separator = '<extra_id_0>'\n",
    "    else: separator = SEP_TOKEN\n",
    "\n",
    "    res: set\n",
    "\n",
    "    if ground_truth:\n",
    "        eos_idx = (tensor == 1).nonzero ()\n",
    "        if eos_idx.numel () > 0:\n",
    "            eos_idx = int (eos_idx [0] [0])\n",
    "        else:\n",
    "            eos_idx = len (tensor)\n",
    "        seq = tensor [:eos_idx]\n",
    "    \n",
    "    else:\n",
    "        seq = tensor [tensor != 0]\n",
    "        seq = seq [seq != - 100]\n",
    "        seq = seq [seq != 1]\n",
    "    \n",
    "    txt = tokenizer.decode (seq)\n",
    "    res = set ([item.strip () for item in txt.split (separator)])\n",
    "\n",
    "    if len (res) > 1:\n",
    "        res -= set ([''])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def sanity_check (preds, labels, to_print = False):\n",
    "\n",
    "    tps_sum = 0\n",
    "    fps_sum = 0\n",
    "    fns_sum = 0 \n",
    "\n",
    "    for i in range (len (labels)):\n",
    "        predicted_set = get_set (preds [i], ground_truth = False)\n",
    "        true_set = get_set (labels [i])\n",
    "\n",
    "        if to_print: print (f'True: {true_set}\\nPred: {predicted_set}')\n",
    "\n",
    "        tps_sum += len (true_set & predicted_set)  # Истинно положительные\n",
    "        fps_sum += len (predicted_set - true_set)     # Ложноположительные\n",
    "        fns_sum += len (true_set - predicted_set)     # Ложноотрицательные\n",
    "\n",
    "    precision = tps_sum / (tps_sum + fps_sum) if (tps_sum + fps_sum) > 0 else 0\n",
    "    recall = tps_sum / (tps_sum + fns_sum) if (tps_sum + fns_sum) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7feda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'train_loss': [], 'val_loss': [], 'precision': [], 'recall': [], 'f1_score': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf665fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "training_steps = len (train_data ['input_ids']) // BATCH_SIZE * num_epochs\n",
    "warmup_steps = int (training_steps * 0.1)\n",
    "print (f'Suggested train steps: {training_steps}\\n\\t warmup steps: {int (training_steps * 0.05)} - {int (training_steps * 0.1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fairseq.optim.adafactor import Adafactor\n",
    "\n",
    "optimizer = AdamW (filter (lambda p: p.requires_grad, model.parameters ()), lr = 1e-5, weight_decay = 0.01)\n",
    "\n",
    "#optimizer = Adafactor (model.parameters (), lr = 3e-5, scale_parameter = False, relative_step = False, weight_decay = 0.02)\n",
    "\n",
    "scheduler = get_scheduler ('linear', optimizer = optimizer, num_warmup_steps = warmup_steps, num_training_steps = training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e76a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_metric = 0\n",
    "\n",
    "for epoch in range (num_epochs):\n",
    "    model.train ()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm (train_loader):\n",
    "        \n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "\n",
    "        outputs = model (input_ids = input_ids, attention_mask = attention_mask, labels = labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item ()\n",
    "\n",
    "        loss.backward ()\n",
    "        optimizer.step ()\n",
    "        optimizer.zero_grad ()\n",
    "\n",
    "        scheduler.step ()\n",
    "\n",
    "        torch.cuda.empty_cache ()\n",
    "    \n",
    "\n",
    "    avg_loss = total_loss / len (train_loader)\n",
    "\n",
    "    metrics ['train_loss'].append ((epoch, avg_loss))\n",
    "\n",
    "    model.eval ()\n",
    "    val_preds, val_labels = [], []\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad ():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch ['input_ids'].to (model.device)\n",
    "            attention_mask = batch ['attention_mask'].to (model.device)\n",
    "            labels = batch ['labels'].to (model.device)\n",
    "\n",
    "            outputs = model.generate (input_ids = input_ids, attention_mask = attention_mask, max_length = SEQ_MAX_LENGTH)\n",
    "\n",
    "            total_val_loss += model (input_ids = input_ids, attention_mask = attention_mask, labels = labels).loss.item ()\n",
    "\n",
    "            val_preds.extend (outputs)\n",
    "            val_labels.extend (labels)\n",
    "\n",
    "            torch.cuda.empty_cache ()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len (val_loader)\n",
    "\n",
    "    prec, recl, f1sc = sanity_check (val_preds, val_labels)\n",
    "\n",
    "    metrics ['val_loss'].append ((epoch, avg_val_loss))\n",
    "    metrics ['precision'].append ((epoch, prec))\n",
    "    metrics ['recall'].append ((epoch, recl))\n",
    "    metrics ['f1_score'].append ((epoch, f1sc))\n",
    "\n",
    "    if prev_metric > avg_val_loss:\n",
    "        prev_model = deepcopy (model.state_dict ())\n",
    "        prev_optimizer = deepcopy (optimizer.state_dict ())\n",
    "        prev_metric = f1sc\n",
    "\n",
    "    print (f'Epoch {epoch + 1} / {num_epochs}, Loss: {avg_loss:.4f}, Validation loss: {avg_val_loss:.4f}, {prec} / {recl} / {f1sc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911466b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (name, history) in enumerate (sorted (metrics.items ())):\n",
    "    plt.figure (figsize = (10, 4))\n",
    "    plt.title (name)\n",
    "    plt.plot (*zip (*history))\n",
    "    plt.grid ()\n",
    "    plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.eval ()\n",
    "val_preds, val_labels = [], []\n",
    "\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (val_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask, max_length=170)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "        torch.cuda.empty_cache ()\n",
    "\n",
    "    print ('Validation: ', sanity_check (val_preds, val_labels))\n",
    "\n",
    "\n",
    "val_preds, val_labels = [], []\n",
    "\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (test_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask, max_length=170)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "        torch.cuda.empty_cache ()\n",
    "\n",
    "    print ('Test: ', sanity_check (val_preds, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict (prev_model)\n",
    "optimizer.load_state_dict (prev_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_preds, val_labels = [], []\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (val_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask, max_length=170)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "        torch.cuda.empty_cache ()\n",
    "\n",
    "    print ('Validation wmax: ', sanity_check (val_preds, val_labels))\n",
    "\n",
    "\n",
    "val_preds, val_labels = [], []\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (test_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask, max_length=170)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "        torch.cuda.empty_cache ()\n",
    "\n",
    "    print ('Test wmax: ', sanity_check (val_preds, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b50d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained('./coint_rut5small_finetune_fulltrain_novalid')\n",
    "#tokenizer.save_pretrained('./coint_rut5small_finetune_fulltrain_novalid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
