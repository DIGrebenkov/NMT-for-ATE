{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461ea578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Enfi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, MT5ForConditionalGeneration, get_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a81f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP_TOKEN = '▁<extra_id_0>'    #' ; '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3b29ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  ABBYY Retrieval & Morphology Engine\\nВ сообщен...   \n",
      "1  Речевые формулы в диалоге\\nПредложенная класси...   \n",
      "2  Географические названия и полнотекстовые докум...   \n",
      "3  Методы автоматического построения специализиро...   \n",
      "4  Закономерности построения дискурсивной последо...   \n",
      "\n",
      "                                               label  \n",
      "0  [[0, 35], [6, 15], [18, 35], [29, 35], [69, 88...  \n",
      "1  [[0, 15], [18, 25], [74, 99], [134, 140], [175...  \n",
      "2  [[0, 23], [26, 50], [54, 68], [169, 190], [181...  \n",
      "3  [[7, 63], [34, 63], [54, 63], [92, 128], [119,...  \n",
      "4  [[26, 57], [62, 76], [251, 265], [266, 280], [...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json ('train_t1_v1.jsonl', lines = True)\n",
    "df.drop (columns = ['id', 'keywords'], inplace = True)\n",
    "print (df.head ())\n",
    "\n",
    "def split_text (text, segments, delimiters = ['...', '.', '?!', '?', '!']):\n",
    "\n",
    "    # Фильтрация\n",
    "    #text = re.sub ('[“”]', '\\\"', text)\n",
    "\n",
    "    # Создаем регулярное выражение для разделителей\n",
    "    delimiters_pattern = '|'.join (map (re.escape, delimiters))\n",
    "    \n",
    "    # Разделяем текст на абзацы\n",
    "    paragraphs = re.split (f'(?<=\\n[ ]*)', text)\n",
    "    \n",
    "    # Список для хранения предложений и их индексов\n",
    "    sentences_with_segments = []\n",
    "    \n",
    "    current_start_index = 0\n",
    "    # Обрабатываем каждый абзац\n",
    "    for paragraph in paragraphs:\n",
    "        # Разделяем абзац на предложения\n",
    "        sentences = re.split (f'(?<=[{delimiters_pattern}] )(?=[A-ZА-ЯЁ])', paragraph)#.strip ())\n",
    "        \n",
    "        # Сопоставляем предложения с сегментами\n",
    "        for sentence in sentences:\n",
    "            # Ищем индексы символов для текущего предложения\n",
    "            start_index = current_start_index\n",
    "            end_index = start_index + len (sentence)\n",
    "\n",
    "            matched_segments = [\n",
    "                text [start: end] for start, end in segments if start >= start_index and end <= end_index\n",
    "            ]\n",
    "            sentences_with_segments.append ((sentence, matched_segments))\n",
    "\n",
    "            current_start_index = end_index\n",
    "    \n",
    "    return sentences_with_segments\n",
    "\n",
    "\n",
    "parallel_text = []\n",
    "parallel_label = []\n",
    "#for i, row in tqdm (df.iterrows (), total = df.shape [0], desc = \"Processing texts: \"):\n",
    "for i, row in df.iterrows ():\n",
    "    text = row ['text']\n",
    "    segments = row ['label']\n",
    "    splitted = split_text (text, segments)\n",
    "    for sentence, terms in splitted:\n",
    "        parallel_text.append (sentence)\n",
    "        constructed_label = ''\n",
    "        for term in terms:\n",
    "            constructed_label += term.strip () + SEP_TOKEN\n",
    "        if len (constructed_label) > 0:\n",
    "            parallel_label.append (constructed_label [: - len (SEP_TOKEN)])\n",
    "        else:\n",
    "            parallel_label.append ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd55c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_MODEL_NAME = 'cointegrated/rut5-small'\n",
    "#USED_MODEL_NAME = './coint_rut5small_finetune_5875'\n",
    "#USED_MODEL_NAME = 'ai-forever/ruT5-base'\n",
    "SEQ_MAX_LENGTH = 150\n",
    "BATCH_SIZE = 2\n",
    "EVAL_BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb823812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "c:\\Users\\Enfi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5TokenizerFast(name_or_path='cointegrated/rut5-small', vocab_size=20200, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20000: AddedToken(\"▁<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20001: AddedToken(\"▁<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20002: AddedToken(\"▁<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20003: AddedToken(\"▁<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20004: AddedToken(\"▁<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20005: AddedToken(\"▁<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20006: AddedToken(\"▁<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20007: AddedToken(\"▁<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20008: AddedToken(\"▁<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20009: AddedToken(\"▁<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20010: AddedToken(\"▁<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20011: AddedToken(\"▁<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20012: AddedToken(\"▁<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20013: AddedToken(\"▁<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20014: AddedToken(\"▁<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20015: AddedToken(\"▁<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20016: AddedToken(\"▁<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20017: AddedToken(\"▁<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20018: AddedToken(\"▁<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20019: AddedToken(\"▁<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20020: AddedToken(\"▁<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20021: AddedToken(\"▁<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20022: AddedToken(\"▁<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20023: AddedToken(\"▁<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20024: AddedToken(\"▁<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20025: AddedToken(\"▁<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20026: AddedToken(\"▁<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20027: AddedToken(\"▁<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20028: AddedToken(\"▁<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20029: AddedToken(\"▁<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20030: AddedToken(\"▁<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20031: AddedToken(\"▁<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20032: AddedToken(\"▁<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20033: AddedToken(\"▁<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20034: AddedToken(\"▁<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20035: AddedToken(\"▁<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20036: AddedToken(\"▁<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20037: AddedToken(\"▁<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20038: AddedToken(\"▁<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20039: AddedToken(\"▁<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20040: AddedToken(\"▁<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20041: AddedToken(\"▁<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20042: AddedToken(\"▁<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20043: AddedToken(\"▁<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20044: AddedToken(\"▁<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20045: AddedToken(\"▁<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20046: AddedToken(\"▁<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20047: AddedToken(\"▁<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20048: AddedToken(\"▁<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20049: AddedToken(\"▁<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20050: AddedToken(\"▁<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20051: AddedToken(\"▁<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20052: AddedToken(\"▁<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20053: AddedToken(\"▁<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20054: AddedToken(\"▁<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20055: AddedToken(\"▁<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20056: AddedToken(\"▁<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20057: AddedToken(\"▁<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20058: AddedToken(\"▁<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20059: AddedToken(\"▁<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20060: AddedToken(\"▁<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20061: AddedToken(\"▁<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20062: AddedToken(\"▁<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20063: AddedToken(\"▁<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20064: AddedToken(\"▁<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20065: AddedToken(\"▁<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20066: AddedToken(\"▁<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20067: AddedToken(\"▁<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20068: AddedToken(\"▁<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20069: AddedToken(\"▁<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20070: AddedToken(\"▁<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20071: AddedToken(\"▁<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20072: AddedToken(\"▁<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20073: AddedToken(\"▁<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20074: AddedToken(\"▁<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20075: AddedToken(\"▁<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20076: AddedToken(\"▁<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20077: AddedToken(\"▁<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20078: AddedToken(\"▁<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20079: AddedToken(\"▁<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20080: AddedToken(\"▁<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20081: AddedToken(\"▁<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20082: AddedToken(\"▁<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20083: AddedToken(\"▁<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20084: AddedToken(\"▁<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20085: AddedToken(\"▁<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20086: AddedToken(\"▁<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20087: AddedToken(\"▁<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20088: AddedToken(\"▁<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20089: AddedToken(\"▁<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20090: AddedToken(\"▁<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20091: AddedToken(\"▁<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20092: AddedToken(\"▁<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20093: AddedToken(\"▁<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20094: AddedToken(\"▁<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20095: AddedToken(\"▁<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20096: AddedToken(\"▁<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20097: AddedToken(\"▁<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20098: AddedToken(\"▁<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20099: AddedToken(\"▁<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20100: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20101: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20102: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20103: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20104: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20105: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20106: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20107: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20108: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20109: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20110: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20111: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20112: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20113: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20114: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20115: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20116: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20117: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20118: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20119: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20120: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20121: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20122: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20123: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20124: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20125: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20126: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20127: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20128: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20129: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20130: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20131: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20132: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20133: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20134: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20135: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20136: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20137: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20138: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20139: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20140: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20141: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20142: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20143: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20144: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20145: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20146: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20147: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20148: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20149: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20150: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20151: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20152: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20153: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20154: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20155: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20156: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20157: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20158: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20159: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20160: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20161: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20162: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20163: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20164: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20165: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20166: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20167: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20168: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20169: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20170: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20171: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20172: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20173: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20174: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20175: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20176: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20177: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20178: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20179: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20180: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20181: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20182: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20183: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20184: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20185: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20186: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20187: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20188: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20189: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20190: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20191: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20192: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20193: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20194: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20195: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20196: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20197: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20198: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20199: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer = T5Tokenizer.from_pretrained (USED_MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained (USED_MODEL_NAME)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a12f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.add_special_tokens ({'additional_special_tokens': str (SEP_TOKEN)})\n",
    "#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1f4ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 5269,  1531,  8484,  9304,   433, 20099,  6972, 17003,     1,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tokenizer (parallel_label [3], padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a74fff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Речевые формулы <extra_id_0> диалоге</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode (enc ['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b31e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_txt, temp_data_txt, train_labels_txt, temp_labels_txt = train_test_split (parallel_text, parallel_label, test_size = 0.2, random_state = 14)\n",
    "val_data_txt, test_data_txt, val_labels_txt, test_labels_txt = train_test_split (temp_data_txt, temp_labels_txt, test_size = 0.5, random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d680ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenizer (train_data_txt, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "train_labels = tokenizer (train_labels_txt, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "\n",
    "val_data = tokenizer (val_data_txt, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "val_labels = tokenizer (val_labels_txt, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "\n",
    "test_data = tokenizer (test_data_txt, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')\n",
    "test_labels = tokenizer (test_labels_txt, padding = 'max_length', truncation = True, max_length = SEQ_MAX_LENGTH, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19a137d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset (Dataset):\n",
    "    def __init__ (self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__ (self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings ['input_ids'] [idx],\n",
    "            'attention_mask': self.encodings ['attention_mask'] [idx],\n",
    "            'labels': self.labels ['input_ids'] [idx]\n",
    "        }\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len (self.encodings ['input_ids'])\n",
    "\n",
    "train_dataset = Seq2SeqDataset (train_data, train_labels)\n",
    "val_dataset = Seq2SeqDataset (val_data, val_labels)\n",
    "test_dataset = Seq2SeqDataset (test_data, test_labels)\n",
    "\n",
    "train_loader = DataLoader (train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader (val_dataset, batch_size = EVAL_BATCH_SIZE)\n",
    "test_loader = DataLoader (test_dataset, batch_size = EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4e6364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained (USED_MODEL_NAME)\n",
    "\n",
    "model.to (device)\n",
    "print (model.device)\n",
    "#model.train ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a1a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set (tensor, ground_truth = True, tokenizer = tokenizer):\n",
    "\n",
    "    separator: str\n",
    "    if SEP_TOKEN == '▁<extra_id_0>': separator = '<extra_id_0>'\n",
    "    else: separator = SEP_TOKEN\n",
    "\n",
    "    res: set\n",
    "\n",
    "    if ground_truth:\n",
    "        eos_idx = (tensor == 1).nonzero ()\n",
    "        if eos_idx.numel () > 0:\n",
    "            eos_idx = int (eos_idx [0] [0])\n",
    "        else:\n",
    "            eos_idx = len (tensor)\n",
    "        seq = tensor [:eos_idx]\n",
    "    \n",
    "    else:\n",
    "        seq = tensor [tensor != 0]\n",
    "        seq = seq [seq != 1]\n",
    "    \n",
    "    txt = tokenizer.decode (seq)\n",
    "    res = set ([item.strip () for item in txt.split (separator)])\n",
    "\n",
    "    if len (res) > 1:\n",
    "        res -= set ([''])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def sanity_check (preds, labels, to_print = False):\n",
    "\n",
    "    tps_sum = 0\n",
    "    fps_sum = 0\n",
    "    fns_sum = 0 \n",
    "\n",
    "    for i in range (len (labels)):\n",
    "        predicted_set = get_set (preds [i], ground_truth = False)\n",
    "        true_set = get_set (labels [i])\n",
    "\n",
    "        if to_print: print (f'True: {true_set}\\nPred: {predicted_set}')\n",
    "\n",
    "        tps_sum += len (true_set & predicted_set)  # Истинно положительные\n",
    "        fps_sum += len (predicted_set - true_set)     # Ложноположительные\n",
    "        fns_sum += len (true_set - predicted_set)     # Ложноотрицательные\n",
    "\n",
    "    precision = tps_sum / (tps_sum + fps_sum) if (tps_sum + fps_sum) > 0 else 0\n",
    "    recall = tps_sum / (tps_sum + fns_sum) if (tps_sum + fns_sum) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dd023e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'train_loss': [], 'val_loss': [], 'precision': [], 'recall': [], 'f1_score': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce8de39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MT5ForConditionalGeneration(\n",
      "  (shared): Embedding(20100, 512)\n",
      "  (encoder): MT5Stack(\n",
      "    (embed_tokens): Embedding(20100, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): MT5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): MT5LayerSelfAttention(\n",
      "            (SelfAttention): MT5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): MT5LayerFF(\n",
      "            (DenseReluDense): MT5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x MT5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): MT5LayerSelfAttention(\n",
      "            (SelfAttention): MT5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): MT5LayerFF(\n",
      "            (DenseReluDense): MT5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): MT5Stack(\n",
      "    (embed_tokens): Embedding(20100, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): MT5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): MT5LayerSelfAttention(\n",
      "            (SelfAttention): MT5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): MT5LayerCrossAttention(\n",
      "            (EncDecAttention): MT5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): MT5LayerFF(\n",
      "            (DenseReluDense): MT5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x MT5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): MT5LayerSelfAttention(\n",
      "            (SelfAttention): MT5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): MT5LayerCrossAttention(\n",
      "            (EncDecAttention): MT5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): MT5LayerFF(\n",
      "            (DenseReluDense): MT5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): MT5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "shared Embedding(20100, 512)\n",
      "--------========--------\n",
      "encoder MT5Stack(\n",
      "  (embed_tokens): Embedding(20100, 512)\n",
      "  (block): ModuleList(\n",
      "    (0): MT5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): MT5LayerSelfAttention(\n",
      "          (SelfAttention): MT5Attention(\n",
      "            (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            (relative_attention_bias): Embedding(32, 6)\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): MT5LayerFF(\n",
      "          (DenseReluDense): MT5DenseGatedActDense(\n",
      "            (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): NewGELUActivation()\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1-7): 7 x MT5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): MT5LayerSelfAttention(\n",
      "          (SelfAttention): MT5Attention(\n",
      "            (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): MT5LayerFF(\n",
      "          (DenseReluDense): MT5DenseGatedActDense(\n",
      "            (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): NewGELUActivation()\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block ModuleList(\n",
      "  (0): MT5Block(\n",
      "    (layer): ModuleList(\n",
      "      (0): MT5LayerSelfAttention(\n",
      "        (SelfAttention): MT5Attention(\n",
      "          (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "          (relative_attention_bias): Embedding(32, 6)\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MT5LayerFF(\n",
      "        (DenseReluDense): MT5DenseGatedActDense(\n",
      "          (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (act): NewGELUActivation()\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1-7): 7 x MT5Block(\n",
      "    (layer): ModuleList(\n",
      "      (0): MT5LayerSelfAttention(\n",
      "        (SelfAttention): MT5Attention(\n",
      "          (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MT5LayerFF(\n",
      "        (DenseReluDense): MT5DenseGatedActDense(\n",
      "          (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (act): NewGELUActivation()\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.0 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "        (relative_attention_bias): Embedding(32, 6)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.0.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      (relative_attention_bias): Embedding(32, 6)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.0.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    (relative_attention_bias): Embedding(32, 6)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  (relative_attention_bias): Embedding(32, 6)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias Embedding(32, 6)\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.0.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.0.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.1 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.1.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.1.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.1.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.1.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.1.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.1.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.2 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.2.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.2.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.2.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.2.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.2.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.2.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.3 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.3.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.3.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.3.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.3.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.3.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.3.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.4 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.4.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.4.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.4.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.4.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.4.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.4.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.5 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.5.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.5.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.5.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.5.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.5.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.5.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.6 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.6.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.6.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.6.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.6.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.6.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.6.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.7 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.7.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.7.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.7.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.7.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.7.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.1 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.block.7.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "encoder.final_layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "encoder.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder MT5Stack(\n",
      "  (embed_tokens): Embedding(20100, 512)\n",
      "  (block): ModuleList(\n",
      "    (0): MT5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): MT5LayerSelfAttention(\n",
      "          (SelfAttention): MT5Attention(\n",
      "            (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            (relative_attention_bias): Embedding(32, 6)\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): MT5LayerCrossAttention(\n",
      "          (EncDecAttention): MT5Attention(\n",
      "            (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): MT5LayerFF(\n",
      "          (DenseReluDense): MT5DenseGatedActDense(\n",
      "            (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): NewGELUActivation()\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1-7): 7 x MT5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): MT5LayerSelfAttention(\n",
      "          (SelfAttention): MT5Attention(\n",
      "            (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): MT5LayerCrossAttention(\n",
      "          (EncDecAttention): MT5Attention(\n",
      "            (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "            (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): MT5LayerFF(\n",
      "          (DenseReluDense): MT5DenseGatedActDense(\n",
      "            (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): NewGELUActivation()\n",
      "          )\n",
      "          (layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block ModuleList(\n",
      "  (0): MT5Block(\n",
      "    (layer): ModuleList(\n",
      "      (0): MT5LayerSelfAttention(\n",
      "        (SelfAttention): MT5Attention(\n",
      "          (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "          (relative_attention_bias): Embedding(32, 6)\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MT5LayerCrossAttention(\n",
      "        (EncDecAttention): MT5Attention(\n",
      "          (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MT5LayerFF(\n",
      "        (DenseReluDense): MT5DenseGatedActDense(\n",
      "          (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (act): NewGELUActivation()\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1-7): 7 x MT5Block(\n",
      "    (layer): ModuleList(\n",
      "      (0): MT5LayerSelfAttention(\n",
      "        (SelfAttention): MT5Attention(\n",
      "          (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MT5LayerCrossAttention(\n",
      "        (EncDecAttention): MT5Attention(\n",
      "          (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "          (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MT5LayerFF(\n",
      "        (DenseReluDense): MT5DenseGatedActDense(\n",
      "          (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (act): NewGELUActivation()\n",
      "        )\n",
      "        (layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "        (relative_attention_bias): Embedding(32, 6)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      (relative_attention_bias): Embedding(32, 6)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    (relative_attention_bias): Embedding(32, 6)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  (relative_attention_bias): Embedding(32, 6)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias Embedding(32, 6)\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.0.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.0.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.0.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.1 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.1.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.1.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.1.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.2 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.2.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.2.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.2.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.3 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.3.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.3.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.3.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.4 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.4.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.4.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.4.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.5 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.5.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.5.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.5.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.6 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.6.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.6.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.6.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.7 MT5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): MT5LayerSelfAttention(\n",
      "      (SelfAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): MT5LayerCrossAttention(\n",
      "      (EncDecAttention): MT5Attention(\n",
      "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): MT5LayerFF(\n",
      "      (DenseReluDense): MT5DenseGatedActDense(\n",
      "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): MT5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer ModuleList(\n",
      "  (0): MT5LayerSelfAttention(\n",
      "    (SelfAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): MT5LayerCrossAttention(\n",
      "    (EncDecAttention): MT5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): MT5LayerFF(\n",
      "    (DenseReluDense): MT5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): MT5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer.0 MT5LayerSelfAttention(\n",
      "  (SelfAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer.0.SelfAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer.0.SelfAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.0.SelfAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.0.SelfAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.0.SelfAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.0.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.7.layer.0.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.1 MT5LayerCrossAttention(\n",
      "  (EncDecAttention): MT5Attention(\n",
      "    (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer.1.EncDecAttention MT5Attention(\n",
      "  (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer.1.EncDecAttention.q Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.1.EncDecAttention.k Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.1.EncDecAttention.v Linear(in_features=512, out_features=384, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.1.EncDecAttention.o Linear(in_features=384, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.1.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.7.layer.1.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.2 MT5LayerFF(\n",
      "  (DenseReluDense): MT5DenseGatedActDense(\n",
      "    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): NewGELUActivation()\n",
      "  )\n",
      "  (layer_norm): MT5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.DenseReluDense MT5DenseGatedActDense(\n",
      "  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): NewGELUActivation()\n",
      ")\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1 Linear(in_features=512, out_features=1024, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.DenseReluDense.wo Linear(in_features=1024, out_features=512, bias=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.DenseReluDense.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.DenseReluDense.act NewGELUActivation()\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.block.7.layer.2.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "decoder.final_layer_norm MT5LayerNorm()\n",
      "--------========--------\n",
      "decoder.dropout Dropout(p=0.1, inplace=False)\n",
      "--------========--------\n",
      "lm_head Linear(in_features=512, out_features=20100, bias=False)\n",
      "--------========--------\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name, module)\n",
    "    print ('--------========--------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1e721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters ():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d07d6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers_by_type (model, layer_type = 'attention'):\n",
    "    for name, param in model.named_parameters ():\n",
    "        if layer_type in name:\n",
    "            param.requires_grad = False\n",
    "            print (f'Layer {name} frozen')\n",
    "        else:\n",
    "            print (f'Layer {name} trainable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2bd62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze_layers_by_type (model, 'encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce0d19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested train steps: 41800\n",
      "\t warmup steps: 2090 - 4180\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "training_steps = len (train_data ['input_ids']) // BATCH_SIZE * num_epochs\n",
    "print (f'Suggested train steps: {training_steps}\\n\\t warmup steps: {int (training_steps * 0.05)} - {int (training_steps * 0.1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82840686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = AdamW (model.parameters (), lr = 1e-5)#, weight_decay = 0.05)\n",
    "optimizer = AdamW (filter (lambda p: p.requires_grad, model.parameters ()), lr = 1e-4, weight_decay = 0.01)\n",
    "#scheduler = lr_scheduler.StepLR (optimizer, warmup_steps = 637, training_steps = 6375)\n",
    "scheduler = get_scheduler ('linear', optimizer = optimizer, num_warmup_steps = 4200, num_training_steps = 42000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b5c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/837 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "100%|██████████| 837/837 [01:05<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 50, Loss: 11.6608, Validation loss: 0.9010, 0.02631578947368421 / 0.005841741901221455 / 0.009561060408518035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [00:58<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 50, Loss: 0.5691, Validation loss: 0.1914, 0.288698955365622 / 0.1614445034519384 / 0.20708446866485014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [00:59<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 50, Loss: 0.2375, Validation loss: 0.1371, 0.4142732811140122 / 0.2527881040892193 / 0.3139841688654354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:10<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 50, Loss: 0.1739, Validation loss: 0.1064, 0.49162011173184356 / 0.3271375464684015 / 0.39285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 50, Loss: 0.1393, Validation loss: 0.0892, 0.5409961685823754 / 0.3749336165693043 / 0.44291091593475534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:10<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 50, Loss: 0.1164, Validation loss: 0.0828, 0.5635930047694754 / 0.37652681890600104 / 0.4514485832537409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 50, Loss: 0.0991, Validation loss: 0.0732, 0.5892179195140471 / 0.4121083377588954 / 0.48500000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 50, Loss: 0.0876, Validation loss: 0.0701, 0.5944487278334618 / 0.4094530005310674 / 0.48490566037735844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 50, Loss: 0.0783, Validation loss: 0.0671, 0.6027293404094011 / 0.4221986192246415 / 0.49656464709556525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 50, Loss: 0.0700, Validation loss: 0.0613, 0.6440809968847352 / 0.4391927774827403 / 0.5222608146510893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 50, Loss: 0.0630, Validation loss: 0.0628, 0.6480314960629922 / 0.43706850770047795 / 0.5220424992071043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 50, Loss: 0.0580, Validation loss: 0.0621, 0.6237698713096139 / 0.43759957514604353 / 0.5143570536828964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / 50, Loss: 0.0523, Validation loss: 0.0590, 0.6591614906832298 / 0.4508762612851832 / 0.5354777672658468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 50, Loss: 0.0479, Validation loss: 0.0586, 0.6529543754674645 / 0.4636218799787573 / 0.5422360248447204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 / 50, Loss: 0.0439, Validation loss: 0.0568, 0.683206106870229 / 0.4753053637812002 / 0.560601315377388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 / 50, Loss: 0.0404, Validation loss: 0.0577, 0.6739469578783152 / 0.45884227296866703 / 0.5459715639810426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 / 50, Loss: 0.0373, Validation loss: 0.0584, 0.6880308880308881 / 0.4731810939989379 / 0.5607300188797987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 50, Loss: 0.0350, Validation loss: 0.0604, 0.6761102603369066 / 0.4689325544344132 / 0.5537786139855754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 / 50, Loss: 0.0329, Validation loss: 0.0591, 0.6922480620155039 / 0.47424322889006904 / 0.5628742514970061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 / 50, Loss: 0.0304, Validation loss: 0.0605, 0.6773700305810397 / 0.4705257567711099 / 0.55531181447822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 50, Loss: 0.0277, Validation loss: 0.0645, 0.6814932486100079 / 0.4556558682952735 / 0.5461489497135582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 / 50, Loss: 0.0273, Validation loss: 0.0606, 0.6911196911196911 / 0.4753053637812002 / 0.5632473253618628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 / 50, Loss: 0.0247, Validation loss: 0.0633, 0.6829457364341085 / 0.467870419543282 / 0.5553104317680428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:10<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 50, Loss: 0.0232, Validation loss: 0.0617, 0.6853415195702226 / 0.47424322889006904 / 0.5605775266792216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 50, Loss: 0.0222, Validation loss: 0.0626, 0.708300395256917 / 0.4758364312267658 / 0.5692503176620075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 / 50, Loss: 0.0211, Validation loss: 0.0626, 0.6854103343465046 / 0.4790228359001593 / 0.5639262269459207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 / 50, Loss: 0.0200, Validation loss: 0.0637, 0.6965944272445821 / 0.47796070100902815 / 0.5669291338582677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 50, Loss: 0.0192, Validation loss: 0.0659, 0.7100545596258768 / 0.4838024429102496 / 0.5754895767530006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 / 50, Loss: 0.0179, Validation loss: 0.0659, 0.7015384615384616 / 0.4843335103558152 / 0.5730442978322338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 / 50, Loss: 0.0171, Validation loss: 0.0641, 0.7079169869331283 / 0.48911311736590546 / 0.5785175879396985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 50, Loss: 0.0163, Validation loss: 0.0672, 0.6852559205500381 / 0.4763674986723314 / 0.56203007518797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 / 50, Loss: 0.0162, Validation loss: 0.0676, 0.7240031274433151 / 0.4917684545937334 / 0.5857052498418722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 / 50, Loss: 0.0146, Validation loss: 0.0671, 0.7062015503875969 / 0.4838024429102496 / 0.5742199810904506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 / 50, Loss: 0.0145, Validation loss: 0.0694, 0.7149532710280374 / 0.4875199150292087 / 0.5797284496368803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 50, Loss: 0.0136, Validation loss: 0.0684, 0.7071651090342679 / 0.48220924057355286 / 0.573413324913167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 / 50, Loss: 0.0133, Validation loss: 0.0692, 0.6996197718631179 / 0.4885820499203399 / 0.5753595997498436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:06<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 / 50, Loss: 0.0122, Validation loss: 0.0699, 0.7096774193548387 / 0.49070631970260226 / 0.5802197802197803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:08<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 50, Loss: 0.0122, Validation loss: 0.0709, 0.7014694508894045 / 0.4816781731279873 / 0.5711586901763224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 / 50, Loss: 0.0117, Validation loss: 0.0701, 0.7074102368220015 / 0.4917684545937334 / 0.5802005012531328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:09<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 / 50, Loss: 0.0112, Validation loss: 0.0707, 0.7147239263803681 / 0.4949548592671269 / 0.5848760589896455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:07<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 50, Loss: 0.0104, Validation loss: 0.0724, 0.7204049844236761 / 0.49123738714816784 / 0.5841490369434797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:05<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 50, Loss: 0.0108, Validation loss: 0.0723, 0.7161741835147745 / 0.48911311736590546 / 0.5812559166929631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:01<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 / 50, Loss: 0.0102, Validation loss: 0.0734, 0.7140625 / 0.48539564524694634 / 0.5779323427126146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [00:59<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 / 50, Loss: 0.0099, Validation loss: 0.0734, 0.7099533437013997 / 0.48486457780138076 / 0.5762070053644682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [00:59<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 50, Loss: 0.0097, Validation loss: 0.0737, 0.7074303405572755 / 0.48539564524694634 / 0.575748031496063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [00:59<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 / 50, Loss: 0.0097, Validation loss: 0.0739, 0.711523588553751 / 0.4885820499203399 / 0.579345088161209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:00<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 / 50, Loss: 0.0092, Validation loss: 0.0737, 0.705108359133127 / 0.4838024429102496 / 0.5738582677165355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:00<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 50, Loss: 0.0094, Validation loss: 0.0746, 0.7091049382716049 / 0.4880509824747743 / 0.5781692356086819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:05<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 / 50, Loss: 0.0089, Validation loss: 0.0743, 0.710077519379845 / 0.48645778013807756 / 0.5773715726441854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:03<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 / 50, Loss: 0.0089, Validation loss: 0.0740, 0.7087529047250194 / 0.485926712692512 / 0.5765595463137997\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (num_epochs):\n",
    "    model.train ()  # Устанавливаем модель в режим обучения\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm (train_loader):\n",
    "        \n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "\n",
    "        outputs = model (input_ids = input_ids, attention_mask = attention_mask, labels = labels)\n",
    "        loss = outputs.loss   ## DOUBLE CHECK if padding ...\n",
    "        total_loss += loss.item ()\n",
    "\n",
    "        loss.backward ()  # Обратное распространение\n",
    "        optimizer.step ()  # Обновление параметров\n",
    "        optimizer.zero_grad ()  # Обнуляем градиенты\n",
    "\n",
    "        scheduler.step ()  # Обновление learning rate\n",
    "    \n",
    "\n",
    "    avg_loss = total_loss / len (train_loader)\n",
    "\n",
    "    metrics ['train_loss'].append ((epoch, avg_loss))\n",
    "\n",
    "    # Оценка на валидационной выборке\n",
    "    model.eval ()  # Устанавливаем модель в режим оценки\n",
    "    val_preds, val_labels = [], []\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad ():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch ['input_ids'].to (model.device)\n",
    "            attention_mask = batch ['attention_mask'].to (model.device)\n",
    "            labels = batch ['labels'].to (model.device)\n",
    "\n",
    "            outputs = model.generate (input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "            total_val_loss += model (input_ids = input_ids, attention_mask = attention_mask, labels = labels).loss.item ()\n",
    "\n",
    "            val_preds.extend (outputs)\n",
    "            val_labels.extend (labels)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len (val_loader)\n",
    "\n",
    "    prec, recl, f1sc = sanity_check (val_preds, val_labels)\n",
    "\n",
    "    metrics ['val_loss'].append ((epoch, avg_val_loss))\n",
    "    metrics ['precision'].append ((epoch, prec))\n",
    "    metrics ['recall'].append ((epoch, recl))\n",
    "    metrics ['f1_score'].append ((epoch, f1sc))\n",
    "\n",
    "    print (f'Epoch {epoch + 1} / {num_epochs}, Loss: {avg_loss:.4f}, Validation loss: {avg_val_loss:.4f}, {prec} / {recl} / {f1sc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41db8f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for param in model.parameters ():\\n    param.requires_grad = True\\n\\nfreeze_layers_by_type (model, 'decoder')\\n\\noptimizer = AdamW (filter (lambda p: p.requires_grad, model.parameters ()), lr = 1e-4, weight_decay = 0.01)\\n\\nscheduler = get_scheduler ('linear', optimizer = optimizer, num_warmup_steps = 2100, num_training_steps = 21000)\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for param in model.parameters ():\n",
    "    param.requires_grad = True\n",
    "\n",
    "freeze_layers_by_type (model, 'decoder')\n",
    "\n",
    "optimizer = AdamW (filter (lambda p: p.requires_grad, model.parameters ()), lr = 1e-4, weight_decay = 0.01)\n",
    "\n",
    "scheduler = get_scheduler ('linear', optimizer = optimizer, num_warmup_steps = 2100, num_training_steps = 21000)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8672aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': [(0, 11.660778895501167), (1, 0.5691289975260037), (2, 0.23748959672137684), (3, 0.17393155913608618), (4, 0.13926328258898238), (5, 0.11636068664597995), (6, 0.09906516643407952), (7, 0.0875781219955556), (8, 0.07831357951579769), (9, 0.06999914564210098), (10, 0.06297172725716942), (11, 0.05796127902007837), (12, 0.05228782013384681), (13, 0.047940822940190704), (14, 0.04386725544505569), (15, 0.040390686355108396), (16, 0.03732154704240933), (17, 0.03503630594561809), (18, 0.03294921687107618), (19, 0.0303929071974125), (20, 0.027695301842287166), (21, 0.027310078528018727), (22, 0.024712362442123333), (23, 0.02324997407255979), (24, 0.02215041170534294), (25, 0.02114051545254125), (26, 0.020003631320729708), (27, 0.01922263506149151), (28, 0.017929593890598276), (29, 0.017079509599678154), (30, 0.016290705112780454), (31, 0.016219215821268944), (32, 0.01463501284858924), (33, 0.01453150626350686), (34, 0.013643333173080585), (35, 0.01332638156581172), (36, 0.012249828825014606), (37, 0.012215426566768849), (38, 0.011725248144358161), (39, 0.011154227434262021), (40, 0.010424488610053923), (41, 0.010791032694476538), (42, 0.010221502385922475), (43, 0.009940745600937613), (44, 0.009674373318741917), (45, 0.009701601691948659), (46, 0.009212174357932196), (47, 0.009441261801270188), (48, 0.008897627190095089), (49, 0.008921712487873084)], 'val_loss': [(0, 0.901005162511553), (1, 0.19144618120931445), (2, 0.13707539148273923), (3, 0.10640513254773049), (4, 0.08919022320991471), (5, 0.08279134567294802), (6, 0.07318187279715424), (7, 0.07014664647479853), (8, 0.06711352774429889), (9, 0.06129624531382606), (10, 0.06278157081632386), (11, 0.06209159249528533), (12, 0.05896166206027071), (13, 0.05855590925507602), (14, 0.05682262770742887), (15, 0.057732058582561356), (16, 0.058364748746334086), (17, 0.060352975305258516), (18, 0.05913013958793488), (19, 0.06047181228087062), (20, 0.06447165830149537), (21, 0.06056824580633215), (22, 0.06331822400513504), (23, 0.061731434121195757), (24, 0.06262535105592439), (25, 0.06260100300645545), (26, 0.06372238043695688), (27, 0.06588245279022625), (28, 0.06585114431966628), (29, 0.06414615640505439), (30, 0.0671654148293393), (31, 0.06764128915965557), (32, 0.06707494468982553), (33, 0.06940812948825104), (34, 0.06844825724228507), (35, 0.0691636267251202), (36, 0.06986538484648225), (37, 0.07090400097714293), (38, 0.07012495085863131), (39, 0.07071742531178253), (40, 0.07242386518489746), (41, 0.07234359332138583), (42, 0.0734213049057871), (43, 0.07344915227897997), (44, 0.07366668062417635), (45, 0.07390064451887848), (46, 0.0737020399776243), (47, 0.07455076828399407), (48, 0.07425415640519488), (49, 0.07403377963762198)], 'precision': [(0, 0.02631578947368421), (1, 0.288698955365622), (2, 0.4142732811140122), (3, 0.49162011173184356), (4, 0.5409961685823754), (5, 0.5635930047694754), (6, 0.5892179195140471), (7, 0.5944487278334618), (8, 0.6027293404094011), (9, 0.6440809968847352), (10, 0.6480314960629922), (11, 0.6237698713096139), (12, 0.6591614906832298), (13, 0.6529543754674645), (14, 0.683206106870229), (15, 0.6739469578783152), (16, 0.6880308880308881), (17, 0.6761102603369066), (18, 0.6922480620155039), (19, 0.6773700305810397), (20, 0.6814932486100079), (21, 0.6911196911196911), (22, 0.6829457364341085), (23, 0.6853415195702226), (24, 0.708300395256917), (25, 0.6854103343465046), (26, 0.6965944272445821), (27, 0.7100545596258768), (28, 0.7015384615384616), (29, 0.7079169869331283), (30, 0.6852559205500381), (31, 0.7240031274433151), (32, 0.7062015503875969), (33, 0.7149532710280374), (34, 0.7071651090342679), (35, 0.6996197718631179), (36, 0.7096774193548387), (37, 0.7014694508894045), (38, 0.7074102368220015), (39, 0.7147239263803681), (40, 0.7204049844236761), (41, 0.7161741835147745), (42, 0.7140625), (43, 0.7099533437013997), (44, 0.7074303405572755), (45, 0.711523588553751), (46, 0.705108359133127), (47, 0.7091049382716049), (48, 0.710077519379845), (49, 0.7087529047250194)], 'recall': [(0, 0.005841741901221455), (1, 0.1614445034519384), (2, 0.2527881040892193), (3, 0.3271375464684015), (4, 0.3749336165693043), (5, 0.37652681890600104), (6, 0.4121083377588954), (7, 0.4094530005310674), (8, 0.4221986192246415), (9, 0.4391927774827403), (10, 0.43706850770047795), (11, 0.43759957514604353), (12, 0.4508762612851832), (13, 0.4636218799787573), (14, 0.4753053637812002), (15, 0.45884227296866703), (16, 0.4731810939989379), (17, 0.4689325544344132), (18, 0.47424322889006904), (19, 0.4705257567711099), (20, 0.4556558682952735), (21, 0.4753053637812002), (22, 0.467870419543282), (23, 0.47424322889006904), (24, 0.4758364312267658), (25, 0.4790228359001593), (26, 0.47796070100902815), (27, 0.4838024429102496), (28, 0.4843335103558152), (29, 0.48911311736590546), (30, 0.4763674986723314), (31, 0.4917684545937334), (32, 0.4838024429102496), (33, 0.4875199150292087), (34, 0.48220924057355286), (35, 0.4885820499203399), (36, 0.49070631970260226), (37, 0.4816781731279873), (38, 0.4917684545937334), (39, 0.4949548592671269), (40, 0.49123738714816784), (41, 0.48911311736590546), (42, 0.48539564524694634), (43, 0.48486457780138076), (44, 0.48539564524694634), (45, 0.4885820499203399), (46, 0.4838024429102496), (47, 0.4880509824747743), (48, 0.48645778013807756), (49, 0.485926712692512)], 'f1_score': [(0, 0.009561060408518035), (1, 0.20708446866485014), (2, 0.3139841688654354), (3, 0.39285714285714285), (4, 0.44291091593475534), (5, 0.4514485832537409), (6, 0.48500000000000004), (7, 0.48490566037735844), (8, 0.49656464709556525), (9, 0.5222608146510893), (10, 0.5220424992071043), (11, 0.5143570536828964), (12, 0.5354777672658468), (13, 0.5422360248447204), (14, 0.560601315377388), (15, 0.5459715639810426), (16, 0.5607300188797987), (17, 0.5537786139855754), (18, 0.5628742514970061), (19, 0.55531181447822), (20, 0.5461489497135582), (21, 0.5632473253618628), (22, 0.5553104317680428), (23, 0.5605775266792216), (24, 0.5692503176620075), (25, 0.5639262269459207), (26, 0.5669291338582677), (27, 0.5754895767530006), (28, 0.5730442978322338), (29, 0.5785175879396985), (30, 0.56203007518797), (31, 0.5857052498418722), (32, 0.5742199810904506), (33, 0.5797284496368803), (34, 0.573413324913167), (35, 0.5753595997498436), (36, 0.5802197802197803), (37, 0.5711586901763224), (38, 0.5802005012531328), (39, 0.5848760589896455), (40, 0.5841490369434797), (41, 0.5812559166929631), (42, 0.5779323427126146), (43, 0.5762070053644682), (44, 0.575748031496063), (45, 0.579345088161209), (46, 0.5738582677165355), (47, 0.5781692356086819), (48, 0.5773715726441854), (49, 0.5765595463137997)]}\n"
     ]
    }
   ],
   "source": [
    "print (metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0baa512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''plt.figure (figsize = (10, 4))\n",
    "for i, (name, history) in enumerate (sorted (metrics.items ())):\n",
    "    plt.subplot (1, len (metrics), i + 1)\n",
    "    plt.title (name)\n",
    "    plt.plot (*zip (*history))\n",
    "    plt.grid ()\n",
    "plt.show ()'''\n",
    "\n",
    "for i, (name, history) in enumerate (sorted (metrics.items ())):\n",
    "    #plt.plot (1, len (metrics), i + 1)\n",
    "    plt.figure (figsize = (10, 4))\n",
    "    plt.title (name)\n",
    "    plt.plot (*zip (*history))\n",
    "    plt.grid ()\n",
    "    plt.show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d87b8734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['семантики <extra_id_0> термина <extra_id_0> терминоведения <extra_id_0> переводоведения <extra_id_0> лексикографии</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'глобальную оптимизацию <extra_id_0> оптимизацию <extra_id_0> генетического алгоритма <extra_id_0> алгоритма <extra_id_0> эвристик <extra_id_0> размерность задачи</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'паузы хезитации <extra_id_0> синтаксической структуры предложения <extra_id_0> предложения <extra_id_0> носителями <extra_id_0> русского языка <extra_id_0> языка</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'словоформ</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      "['семантики <extra_id_0> термина <extra_id_0> терминоведения <extra_id_0> переводоведения <extra_id_0> лексикографии</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'глобальную оптимизацию <extra_id_0> оптимизацию <extra_id_0> генетического алгоритма <extra_id_0> эвалгоритма <extra_id_0> эвристик <extra_id_0> допуность задачи</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'паузы <extra_id_0>зитации <extra_id_0> хетаксической структуры предложения <extra_id_0> предложения <extra_id_0> носителями <extra_id_0> русского языка <extra_id_0> языка</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'форм</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      "True: {'терминоведения', 'семантики', 'лексикографии', 'переводоведения', 'термина'}\n",
      "Pred: {'терминоведения', 'семантики', 'лексикографии', 'переводоведения', 'термина'}\n",
      "True: {'генетического алгоритма', 'алгоритма', 'оптимизацию', 'размерность задачи', 'глобальную оптимизацию', 'эвристик'}\n",
      "Pred: {'генетического алгоритма', 'эвалгоритма', 'оптимизацию', 'глобальную оптимизацию', 'допуность задачи', 'эвристик'}\n",
      "True: {'синтаксической структуры предложения', 'русского языка', 'носителями', 'предложения', 'языка', 'паузы хезитации'}\n",
      "Pred: {'русского языка', 'носителями', 'предложения', 'языка', 'паузы', 'зитации', 'хетаксической структуры предложения'}\n",
      "True: {'словоформ'}\n",
      "Pred: {'форм'}\n",
      "(0.6842105263157895, 0.7222222222222222, 0.7027027027027027)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "\n",
    "        outputs = model (input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        outputs = outputs.logits.argmax(-1)\n",
    "\n",
    "        #print (outputs)\n",
    "        print (tokenizer.batch_decode (labels))\n",
    "        print (tokenizer.batch_decode (outputs))\n",
    "\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "        print (sanity_check (outputs, labels, to_print = True))\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49e10ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:20<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  (0.7087529047250194, 0.485926712692512, 0.5765595463137997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:19<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  (0.7087872185911401, 0.5464725643896976, 0.6171356307303194)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.eval ()  # Устанавливаем модель в режим оценки\n",
    "val_preds, val_labels = [], []\n",
    "\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (val_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "    print ('Validation: ', sanity_check (val_preds, val_labels))\n",
    "\n",
    "\n",
    "val_preds, val_labels = [], []\n",
    "\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (test_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "    print ('Test: ', sanity_check (val_preds, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c0a2d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:48<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation wmax:  (0.7934272300469484, 0.8077535847052576, 0.8005263157894736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:44<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test wmax:  (0.7756911841418883, 0.8325867861142218, 0.8031325951930868)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_BEAMS = 1\n",
    "\n",
    "val_preds, val_labels = [], []\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (val_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask, max_length=SEQ_MAX_LENGTH)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "    print ('Validation wmax: ', sanity_check (val_preds, val_labels))\n",
    "\n",
    "\n",
    "val_preds, val_labels = [], []\n",
    "with torch.no_grad ():\n",
    "    for batch in tqdm (test_loader):\n",
    "        input_ids = batch ['input_ids'].to (model.device)\n",
    "        attention_mask = batch ['attention_mask'].to (model.device)\n",
    "        labels = batch ['labels'].to (model.device)\n",
    "        out = model.generate (input_ids = input_ids, attention_mask = attention_mask, max_length=SEQ_MAX_LENGTH)\n",
    "\n",
    "        val_preds.extend (out)\n",
    "        val_labels.extend (labels)\n",
    "\n",
    "    print ('Test wmax: ', sanity_check (val_preds, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "158c7e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,   544, 19868,   657, 20099, 10332,   308, 20099, 10332,   411,\n",
       "         6335, 20099,  8419,   411,  6335, 20099, 17374,  1040, 17519,     1,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205f85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./coint_rut5small_finetune_6171-8031\\\\tokenizer_config.json',\n",
       " './coint_rut5small_finetune_6171-8031\\\\special_tokens_map.json',\n",
       " './coint_rut5small_finetune_6171-8031\\\\spiece.model',\n",
       " './coint_rut5small_finetune_6171-8031\\\\added_tokens.json',\n",
       " './coint_rut5small_finetune_6171-8031\\\\tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_pretrained('./coint_rut5small_finetune_6171-8031')\n",
    "#tokenizer.save_pretrained('./coint_rut5small_finetune_6171-8031')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39be4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = { \n",
    "#    'epoch': 50,\n",
    "#    'model': model.state_dict(),\n",
    "#    'optimizer': optimizer.state_dict()}\n",
    "#torch.save (checkpoint, './coint_rut5small_finetune_6171-8031/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3a51a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
